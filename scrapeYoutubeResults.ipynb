{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import downloadPermission\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from googleapiclient.discovery import build, build_from_document\n",
    "from googleapiclient.errors import HttpError\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from apiclient.discovery import build\n",
    "from oauth2client.tools import argparser, run_flow\n",
    "from oauth2client.client import flow_from_clientsecrets\n",
    "from oauth2client.file import Storage\n",
    "\n",
    "def SearchVid(search, pages):\n",
    "    video_id =[]\n",
    "    for page in range(1,pages+1):\n",
    "        if(page % 5 == 0):\n",
    "            print(page)\n",
    "        responce = urllib.request.urlopen('https://www.youtube.com/results?search_query='+search+'&page='+str(page))\n",
    "\n",
    "        soup = BeautifulSoup(responce)    \n",
    "        divs = soup.find_all(\"div\", { \"class\" : \"yt-lockup-content\"})\n",
    "\n",
    "\n",
    "        for i in divs:\n",
    "            href= i.find('a', href=True)\n",
    "            video_id.append(href['href'])\n",
    "            \n",
    "    return video_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not sponsored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The CLIENT_SECRETS_FILE variable specifies the name of a file that contains\n",
    "# the OAuth 2.0 information for this application, including its client_id and\n",
    "# client_secret.\n",
    "CLIENT_SECRETS_FILE = \"client_secret_local.json\"\n",
    "\n",
    "# This OAuth 2.0 access scope allows for full read/write access to the\n",
    "# authenticated user's account and requires requests to use an SSL connection.\n",
    "SCOPES = ['https://www.googleapis.com/auth/youtube.force-ssl']\n",
    "API_SERVICE_NAME = 'youtube'\n",
    "API_VERSION = 'v3'\n",
    "\n",
    "# Set DEVELOPER_KEY to the API key value from the APIs & auth > Registered apps\n",
    "# tab of\n",
    "#   https://cloud.google.com/console\n",
    "# Please ensure that you have enabled the YouTube Data API for your project.\n",
    "DEVELOPER_KEY = \"AIzaSyBfKNCrt6VI_qvB8YzzCT2t4foVhVrw0uU\"\n",
    "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
    "YOUTUBE_API_VERSION = \"v3\"\n",
    "\n",
    "youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION,\n",
    "    developerKey=DEVELOPER_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "SearchString = \"not sponsored\"\n",
    "video_id = SearchVid(SearchString.replace(\" \", \"%20\"), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/watch?v=Q5oXLF3TlTs',\n",
       " '/watch?v=_XlB1bTvDHo',\n",
       " '/watch?v=0z5kMdxnj48',\n",
       " '/watch?v=yeuLoclmuPQ',\n",
       " '/watch?v=TyDT6CQhfx8',\n",
       " '/channel/UCJFqxqIgjpiPZMqs4VgGCFA']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_id[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_video = ['/watch?v=' in i for i in video_id]\n",
    "only_videos = [i for (i, v) in zip(video_id, is_video) if v]\n",
    "video_ids = [i.replace('/watch?v=','') for i in only_videos]\n",
    "\n",
    "only_video = ['&list' not in i for i in sp_video_ids]\n",
    "video_ids = [i for (i, v) in zip(sp_video_ids, sp_is_only_video) if v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q5oXLF3TlTs', '_XlB1bTvDHo', '0z5kMdxnj48', 'yeuLoclmuPQ', 'TyDT6CQhfx8', '8LjhIP5elx0', 'YH6f7UxKeAk', 'hAwAYPxRb24', 'HQts7Xv-Y7k', '1xbI7kQZ3Cw']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "452"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(video_ids[:10])\n",
    "len(video_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "descriptions = []\n",
    "channels = []\n",
    "captions =[]\n",
    "\n",
    "for video in video_ids:\n",
    "    video_response = youtube.videos().list(part = 'snippet',\n",
    "                                                id = video\n",
    "                                               ).execute()\n",
    "\n",
    "    titles.append(video_response['items'][0]['snippet']['title'])\n",
    "    descriptions.append(video_response['items'][0]['snippet']['description'])\n",
    "    channels.append(video_response['items'][0]['snippet']['channelTitle'])\n",
    "    \n",
    "    try:\n",
    "        captions.append(downloadPermission.download_caption_byVidID(video, tfmt=\"srt\"))\n",
    "    except(HttpError, IndexError):\n",
    "        captions.append(None)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([i is not None for i in captions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>title</th>\n",
       "      <th>video_id</th>\n",
       "      <th>description</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>emma chamberlain</td>\n",
       "      <td>Zaful Review &amp; Try On Haul! GENUINE, HONEST, &amp;...</td>\n",
       "      <td>YH6f7UxKeAk</td>\n",
       "      <td>thanks for stoppin by, hope you enjoyed:) i pl...</td>\n",
       "      <td>b\"1\\n00:00:06,020 --&gt; 00:00:12,600\\nhey guys i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>QueenDebbie</td>\n",
       "      <td>WTF FASHION NOVA | MY EXPERIENCE *NOT SPONSORED*</td>\n",
       "      <td>zYb_n4MP2oI</td>\n",
       "      <td>COMMENT,LIKE ,AN SUBSCRIBE\\n------------------...</td>\n",
       "      <td>b\"1\\n00:00:01,060 --&gt; 00:00:05,890\\n[Music]\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>fit_geo</td>\n",
       "      <td>NOT Sponsored Gymshark Haul &amp; Review With Meas...</td>\n",
       "      <td>ci-R2CnyDpo</td>\n",
       "      <td>Hey guys! Finally figuring out some of this ed...</td>\n",
       "      <td>b\"1\\n00:00:00,860 --&gt; 00:00:09,389\\nwhat's up ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>AlexGoPow</td>\n",
       "      <td>CSGOLive Honest Opening - THE 8$ KNIFE OPENING...</td>\n",
       "      <td>KBzh1R4swmE</td>\n",
       "      <td>USE CODE \"alexgopow\" : https://www.csgolive.co...</td>\n",
       "      <td>b\"1\\n00:00:00,030 --&gt; 00:00:03,480\\nhey guys A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>VICARI</td>\n",
       "      <td>HONEST HP Sprocket Portable Printer REVIEW (No...</td>\n",
       "      <td>KRF16bsC0ps</td>\n",
       "      <td>I purchased the HP Sprocket printer as a porta...</td>\n",
       "      <td>b\"1\\n00:00:00,000 --&gt; 00:00:05,700\\nhi everybo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             channel                                              title  \\\n",
       "6   emma chamberlain  Zaful Review & Try On Haul! GENUINE, HONEST, &...   \n",
       "19       QueenDebbie   WTF FASHION NOVA | MY EXPERIENCE *NOT SPONSORED*   \n",
       "30           fit_geo  NOT Sponsored Gymshark Haul & Review With Meas...   \n",
       "46         AlexGoPow  CSGOLive Honest Opening - THE 8$ KNIFE OPENING...   \n",
       "52            VICARI  HONEST HP Sprocket Portable Printer REVIEW (No...   \n",
       "\n",
       "       video_id                                        description  \\\n",
       "6   YH6f7UxKeAk  thanks for stoppin by, hope you enjoyed:) i pl...   \n",
       "19  zYb_n4MP2oI  COMMENT,LIKE ,AN SUBSCRIBE\\n------------------...   \n",
       "30  ci-R2CnyDpo  Hey guys! Finally figuring out some of this ed...   \n",
       "46  KBzh1R4swmE  USE CODE \"alexgopow\" : https://www.csgolive.co...   \n",
       "52  KRF16bsC0ps  I purchased the HP Sprocket printer as a porta...   \n",
       "\n",
       "                                              caption  \n",
       "6   b\"1\\n00:00:06,020 --> 00:00:12,600\\nhey guys i...  \n",
       "19  b\"1\\n00:00:01,060 --> 00:00:05,890\\n[Music]\\n\\...  \n",
       "30  b\"1\\n00:00:00,860 --> 00:00:09,389\\nwhat's up ...  \n",
       "46  b\"1\\n00:00:00,030 --> 00:00:03,480\\nhey guys A...  \n",
       "52  b\"1\\n00:00:00,000 --> 00:00:05,700\\nhi everybo...  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(list(zip(channels, titles, video_ids, descriptions, captions)))\n",
    "data_with_captions = data.dropna()\n",
    "data_with_captions.columns=['channel','title', 'video_id', 'description', 'caption']\n",
    "data_with_captions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:3110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>title</th>\n",
       "      <th>video_id</th>\n",
       "      <th>description</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>emma chamberlain</td>\n",
       "      <td>Zaful Review &amp; Try On Haul! GENUINE, HONEST, &amp;...</td>\n",
       "      <td>YH6f7UxKeAk</td>\n",
       "      <td>thanks for stoppin by, hope you enjoyed:) i pl...</td>\n",
       "      <td>1\\n00:00:06,020 --&gt; 00:00:12,600\\nhey guys it'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>QueenDebbie</td>\n",
       "      <td>WTF FASHION NOVA | MY EXPERIENCE *NOT SPONSORED*</td>\n",
       "      <td>zYb_n4MP2oI</td>\n",
       "      <td>COMMENT,LIKE ,AN SUBSCRIBE\\n------------------...</td>\n",
       "      <td>1\\n00:00:01,060 --&gt; 00:00:05,890\\n[Music]\\n\\n2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>fit_geo</td>\n",
       "      <td>NOT Sponsored Gymshark Haul &amp; Review With Meas...</td>\n",
       "      <td>ci-R2CnyDpo</td>\n",
       "      <td>Hey guys! Finally figuring out some of this ed...</td>\n",
       "      <td>1\\n00:00:00,860 --&gt; 00:00:09,389\\nwhat's up gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>AlexGoPow</td>\n",
       "      <td>CSGOLive Honest Opening - THE 8$ KNIFE OPENING...</td>\n",
       "      <td>KBzh1R4swmE</td>\n",
       "      <td>USE CODE \"alexgopow\" : https://www.csgolive.co...</td>\n",
       "      <td>1\\n00:00:00,030 --&gt; 00:00:03,480\\nhey guys Ale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>VICARI</td>\n",
       "      <td>HONEST HP Sprocket Portable Printer REVIEW (No...</td>\n",
       "      <td>KRF16bsC0ps</td>\n",
       "      <td>I purchased the HP Sprocket printer as a porta...</td>\n",
       "      <td>1\\n00:00:00,000 --&gt; 00:00:05,700\\nhi everybody...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             channel                                              title  \\\n",
       "6   emma chamberlain  Zaful Review & Try On Haul! GENUINE, HONEST, &...   \n",
       "19       QueenDebbie   WTF FASHION NOVA | MY EXPERIENCE *NOT SPONSORED*   \n",
       "30           fit_geo  NOT Sponsored Gymshark Haul & Review With Meas...   \n",
       "46         AlexGoPow  CSGOLive Honest Opening - THE 8$ KNIFE OPENING...   \n",
       "52            VICARI  HONEST HP Sprocket Portable Printer REVIEW (No...   \n",
       "\n",
       "       video_id                                        description  \\\n",
       "6   YH6f7UxKeAk  thanks for stoppin by, hope you enjoyed:) i pl...   \n",
       "19  zYb_n4MP2oI  COMMENT,LIKE ,AN SUBSCRIBE\\n------------------...   \n",
       "30  ci-R2CnyDpo  Hey guys! Finally figuring out some of this ed...   \n",
       "46  KBzh1R4swmE  USE CODE \"alexgopow\" : https://www.csgolive.co...   \n",
       "52  KRF16bsC0ps  I purchased the HP Sprocket printer as a porta...   \n",
       "\n",
       "                                              caption  \n",
       "6   1\\n00:00:06,020 --> 00:00:12,600\\nhey guys it'...  \n",
       "19  1\\n00:00:01,060 --> 00:00:05,890\\n[Music]\\n\\n2...  \n",
       "30  1\\n00:00:00,860 --> 00:00:09,389\\nwhat's up gu...  \n",
       "46  1\\n00:00:00,030 --> 00:00:03,480\\nhey guys Ale...  \n",
       "52  1\\n00:00:00,000 --> 00:00:05,700\\nhi everybody...  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_captions.caption = [i.decode(\"utf-8\") for i in data_with_captions.caption] \n",
    "data_with_captions = data_with_captions[(data_with_captions.caption!='')]\n",
    "data_with_captions = data_with_captions.drop_duplicates(subset = 'video_id')\n",
    "data_with_captions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def srt_time_to_seconds(time):\n",
    "    split_time=time.split(',')\n",
    "    major, minor = (split_time[0].split(':'), split_time[1])\n",
    "    return int(major[0])*1440 + int(major[1])*60 + int(major[2]) + float(minor)/1000\n",
    "\n",
    "def srt_to_dict(srtText):\n",
    "    subs=[]\n",
    "    for s in re.sub('\\r\\n', '\\n', srtText).split('\\n\\n'):\n",
    "        st = s.split('\\n')\n",
    "        if len(st)>=3:\n",
    "            split = st[1].split(' --> ')\n",
    "            subs.append({'start': srt_time_to_seconds(split[0].strip()),\n",
    "                         'end': srt_time_to_seconds(split[1].strip()),\n",
    "                         'text': '<br />'.join(j for j in st[2:len(st)])\n",
    "                        })\n",
    "    return subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end</th>\n",
       "      <th>start</th>\n",
       "      <th>text</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.60</td>\n",
       "      <td>6.02</td>\n",
       "      <td>hey guys it's Emma so today I'm going to</td>\n",
       "      <td>YH6f7UxKeAk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.52</td>\n",
       "      <td>9.27</td>\n",
       "      <td>be doing an unbiased unspun surd Zappa</td>\n",
       "      <td>YH6f7UxKeAk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.59</td>\n",
       "      <td>12.60</td>\n",
       "      <td>Hall South Pole likes to partner with a</td>\n",
       "      <td>YH6f7UxKeAk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.75</td>\n",
       "      <td>14.52</td>\n",
       "      <td>lot of youtubers and send them products</td>\n",
       "      <td>YH6f7UxKeAk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.42</td>\n",
       "      <td>16.59</td>\n",
       "      <td>so that they can do a haul for them me</td>\n",
       "      <td>YH6f7UxKeAk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     end  start                                      text     video_id\n",
       "0  12.60   6.02  hey guys it's Emma so today I'm going to  YH6f7UxKeAk\n",
       "1  14.52   9.27    be doing an unbiased unspun surd Zappa  YH6f7UxKeAk\n",
       "2  16.59  12.60   Hall South Pole likes to partner with a  YH6f7UxKeAk\n",
       "3  18.75  14.52   lot of youtubers and send them products  YH6f7UxKeAk\n",
       "4  21.42  16.59    so that they can do a haul for them me  YH6f7UxKeAk"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captionTable = pd.DataFrame(columns =['end', 'start', 'text', 'video_id'] )\n",
    "\n",
    "for i in range(len(data_with_captions)):\n",
    "    vid = data_with_captions.video_id.iloc[i]\n",
    "    cap_new = pd.DataFrame.from_dict(srt_to_dict(data_with_captions.caption.iloc[i]))\n",
    "    cap_new['video_id'] = vid\n",
    "    #if i == 209:\n",
    "        #print(cap_new)\n",
    "    captionTable = captionTable.append(cap_new)\n",
    "    #print(vid)\n",
    "    #print(i)\n",
    "\n",
    "captionTable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedCaptions = list(captionTable.groupby('video_id')['text'].agg(\" \".join)[data_with_captions.video_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>title</th>\n",
       "      <th>video_id</th>\n",
       "      <th>description</th>\n",
       "      <th>caption</th>\n",
       "      <th>fullCaptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>emma chamberlain</td>\n",
       "      <td>Zaful Review &amp; Try On Haul! GENUINE, HONEST, &amp;...</td>\n",
       "      <td>YH6f7UxKeAk</td>\n",
       "      <td>thanks for stoppin by, hope you enjoyed:) i pl...</td>\n",
       "      <td>1\\n00:00:06,020 --&gt; 00:00:12,600\\nhey guys it'...</td>\n",
       "      <td>hey guys it's Emma so today I'm going to be do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>QueenDebbie</td>\n",
       "      <td>WTF FASHION NOVA | MY EXPERIENCE *NOT SPONSORED*</td>\n",
       "      <td>zYb_n4MP2oI</td>\n",
       "      <td>COMMENT,LIKE ,AN SUBSCRIBE\\n------------------...</td>\n",
       "      <td>1\\n00:00:01,060 --&gt; 00:00:05,890\\n[Music]\\n\\n2...</td>\n",
       "      <td>[Music] to provide you with an amazing challen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>fit_geo</td>\n",
       "      <td>NOT Sponsored Gymshark Haul &amp; Review With Meas...</td>\n",
       "      <td>ci-R2CnyDpo</td>\n",
       "      <td>Hey guys! Finally figuring out some of this ed...</td>\n",
       "      <td>1\\n00:00:00,860 --&gt; 00:00:09,389\\nwhat's up gu...</td>\n",
       "      <td>what's up guys so I got a super huge kind of u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>AlexGoPow</td>\n",
       "      <td>CSGOLive Honest Opening - THE 8$ KNIFE OPENING...</td>\n",
       "      <td>KBzh1R4swmE</td>\n",
       "      <td>USE CODE \"alexgopow\" : https://www.csgolive.co...</td>\n",
       "      <td>1\\n00:00:00,030 --&gt; 00:00:03,480\\nhey guys Ale...</td>\n",
       "      <td>hey guys Alex here before this video starts wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>VICARI</td>\n",
       "      <td>HONEST HP Sprocket Portable Printer REVIEW (No...</td>\n",
       "      <td>KRF16bsC0ps</td>\n",
       "      <td>I purchased the HP Sprocket printer as a porta...</td>\n",
       "      <td>1\\n00:00:00,000 --&gt; 00:00:05,700\\nhi everybody...</td>\n",
       "      <td>hi everybody its Chelsea and today I'm going t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             channel                                              title  \\\n",
       "6   emma chamberlain  Zaful Review & Try On Haul! GENUINE, HONEST, &...   \n",
       "19       QueenDebbie   WTF FASHION NOVA | MY EXPERIENCE *NOT SPONSORED*   \n",
       "30           fit_geo  NOT Sponsored Gymshark Haul & Review With Meas...   \n",
       "46         AlexGoPow  CSGOLive Honest Opening - THE 8$ KNIFE OPENING...   \n",
       "52            VICARI  HONEST HP Sprocket Portable Printer REVIEW (No...   \n",
       "\n",
       "       video_id                                        description  \\\n",
       "6   YH6f7UxKeAk  thanks for stoppin by, hope you enjoyed:) i pl...   \n",
       "19  zYb_n4MP2oI  COMMENT,LIKE ,AN SUBSCRIBE\\n------------------...   \n",
       "30  ci-R2CnyDpo  Hey guys! Finally figuring out some of this ed...   \n",
       "46  KBzh1R4swmE  USE CODE \"alexgopow\" : https://www.csgolive.co...   \n",
       "52  KRF16bsC0ps  I purchased the HP Sprocket printer as a porta...   \n",
       "\n",
       "                                              caption  \\\n",
       "6   1\\n00:00:06,020 --> 00:00:12,600\\nhey guys it'...   \n",
       "19  1\\n00:00:01,060 --> 00:00:05,890\\n[Music]\\n\\n2...   \n",
       "30  1\\n00:00:00,860 --> 00:00:09,389\\nwhat's up gu...   \n",
       "46  1\\n00:00:00,030 --> 00:00:03,480\\nhey guys Ale...   \n",
       "52  1\\n00:00:00,000 --> 00:00:05,700\\nhi everybody...   \n",
       "\n",
       "                                         fullCaptions  \n",
       "6   hey guys it's Emma so today I'm going to be do...  \n",
       "19  [Music] to provide you with an amazing challen...  \n",
       "30  what's up guys so I got a super huge kind of u...  \n",
       "46  hey guys Alex here before this video starts wi...  \n",
       "52  hi everybody its Chelsea and today I'm going t...  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_captions['fullCaptions']=combinedCaptions\n",
    "data_with_captions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_with_captions.to_pickle(\"notSponsored_scrape.pickle\")\n",
    "captionTable.to_pickle(\"notSponsored_captions_scrape.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sponsored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "SearchString = \"video is sponsored\"\n",
    "sp_video_id = SearchVid(SearchString.replace(\" \", \"%20\"), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_is_video = ['/watch?v=' in i for i in sp_video_id]\n",
    "sp_only_videos = [i for (i, v) in zip(sp_video_id, sp_is_video) if v]\n",
    "sp_video_ids = [i.replace('/watch?v=','') for i in sp_only_videos]\n",
    "\n",
    "sp_is_only_video = ['&list' not in i for i in sp_video_ids]\n",
    "sp_video_ids = [i for (i, v) in zip(sp_video_ids, sp_is_only_video) if v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "HttpError",
     "evalue": "<HttpError 403 when requesting https://www.googleapis.com/youtube/v3/videos?part=snippet&id=ZpTW04Sho6s&key=AIzaSyBfKNCrt6VI_qvB8YzzCT2t4foVhVrw0uU&alt=json returned \"The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.\">",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-c8df7d7ba6e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvideo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mns_video_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     video_response = youtube.videos().list(part = 'snippet',\n\u001b[0;32m----> 8\u001b[0;31m                                                 \u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                                                ).execute()\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/oauth2client/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mpositional_parameters_enforcement\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPOSITIONAL_WARNING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpositional_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    840\u001b[0m       \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHttpError\u001b[0m: <HttpError 403 when requesting https://www.googleapis.com/youtube/v3/videos?part=snippet&id=ZpTW04Sho6s&key=AIzaSyBfKNCrt6VI_qvB8YzzCT2t4foVhVrw0uU&alt=json returned \"The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.\">"
     ]
    }
   ],
   "source": [
    "sp_titles = []\n",
    "sp_descriptions = []\n",
    "sp_channels = []\n",
    "sp_captions =[]\n",
    "\n",
    "for video in sp_video_ids:\n",
    "    video_response = youtube.videos().list(part = 'snippet',\n",
    "                                                id = video\n",
    "                                               ).execute()\n",
    "\n",
    "    sp_titles.append(video_response['items'][0]['snippet']['title'])\n",
    "    sp_descriptions.append(video_response['items'][0]['snippet']['description'])\n",
    "    sp_channels.append(video_response['items'][0]['snippet']['channelTitle'])\n",
    "    \n",
    "    try:\n",
    "        sp_captions.append(downloadPermission.download_caption_byVidID(video, tfmt=\"srt\"))\n",
    "    except(HttpError, IndexError):\n",
    "        sp_captions.append(None)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_data = pd.DataFrame(list(zip(sp_channels, sp_titles, sp_video_ids, sp_descriptions, sp_captions)))\n",
    "sp_data_with_captions = sp_data.dropna()\n",
    "sp_data_with_captions.columns=['channel','title', 'video_id', 'description', 'caption']\n",
    "sp_data_with_captions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_data_with_captions.caption = [i.decode(\"utf-8\") for i in sp_data_with_captions.caption] \n",
    "sp_data_with_captions = sp_data_with_captions[(sp_data_with_captions.caption!='')]\n",
    "sp_data_with_captions = sp_data_with_captions.drop_duplicates(subset = 'video_id')\n",
    "sp_data_with_captions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_captionTable = pd.DataFrame(columns =['end', 'start', 'text', 'video_id'] )\n",
    "\n",
    "for i in range(len(sp_data_with_captions)):\n",
    "    vid = sp_data_with_captions.video_id.iloc[i]\n",
    "    cap_new = pd.DataFrame.from_dict(srt_to_dict(sp_data_with_captions.caption.iloc[i]))\n",
    "    cap_new['video_id'] = vid\n",
    "    #if i == 209:\n",
    "        #print(cap_new)\n",
    "    sp_captionTable = sp_captionTable.append(cap_new)\n",
    "    #print(vid)\n",
    "    #print(i)\n",
    "\n",
    "sp_captionTable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_combinedCaptions = list(sp_captionTable.groupby('video_id')['text'].agg(\" \".join)[sp_data_with_captions.video_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_data_with_captions['fullCaptions']=sp_combinedCaptions\n",
    "sp_data_with_captions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp_data_with_captions.to_pickle(\"sponsored_scrape.pickle\")\n",
    "sp_captionTable.to_pickle(\"sponsored_captions_scrape.pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
