{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import httplib2\n",
    "import sys\n",
    "import google.oauth2.credentials\n",
    "import google_auth_oauthlib.flow\n",
    "\n",
    "from googleapiclient.discovery import build, build_from_document\n",
    "from googleapiclient.errors import HttpError\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from apiclient.discovery import build\n",
    "from oauth2client.tools import argparser, run_flow\n",
    "from oauth2client.client import flow_from_clientsecrets\n",
    "from oauth2client.file import Storage\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import downloadPermission\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "import re\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "import pickle\n",
    "\n",
    "from nltk.tokenize import word_tokenize # or use some other tokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>channel</th>\n",
       "      <th>title</th>\n",
       "      <th>video_id</th>\n",
       "      <th>description</th>\n",
       "      <th>captions</th>\n",
       "      <th>sponsored</th>\n",
       "      <th>fullCaptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>810</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>WINNERS Curry Set Giveaway</td>\n",
       "      <td>CQTp_Hh8qH4</td>\n",
       "      <td>Announcing the winners of the Popin Cookin' Ka...</td>\n",
       "      <td>1\\n00:00:06,680 --&gt; 00:00:11,519\\nhi everyone ...</td>\n",
       "      <td>no</td>\n",
       "      <td>grins uglies hides and we welcome back to anot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>811</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>PEZ giveaway WINNERS</td>\n",
       "      <td>stpWXStiw4k</td>\n",
       "      <td>Watch to find out if you're one of the lucky w...</td>\n",
       "      <td>1\\n00:00:08,540 --&gt; 00:00:13,200\\nhello everyb...</td>\n",
       "      <td>no</td>\n",
       "      <td>hello everybody I'm back again and it's it's s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>814</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>PEZ Whatcha Eating #82</td>\n",
       "      <td>yJfm6wFnr2s</td>\n",
       "      <td>[GIVEAWAY CLOSED] Eating old fashioned PEZ can...</td>\n",
       "      <td>1\\n00:00:08,470 --&gt; 00:00:15,980\\nhello everyb...</td>\n",
       "      <td>no</td>\n",
       "      <td>greetings my lovelies hi and welcome back to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>815</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>Gummy Burger Set - Lunch Bag: Whatcha Eating? #81</td>\n",
       "      <td>9cbb_kdUspU</td>\n",
       "      <td>[GIVEAWAY CLOSED] A miniature gummy version of...</td>\n",
       "      <td>1\\n00:00:07,910 --&gt; 00:00:14,639\\nhi everybody...</td>\n",
       "      <td>no</td>\n",
       "      <td>everybody it's a me and I'm back and I'm still...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>836</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>Giveaway Winners - Chocolat de Tomato</td>\n",
       "      <td>R-VvqR0EFNk</td>\n",
       "      <td>Wanna try Japanese tomato chocolate for yourse...</td>\n",
       "      <td>1\\n00:00:07,280 --&gt; 00:00:12,870\\nhello you tw...</td>\n",
       "      <td>no</td>\n",
       "      <td>frooty frooty frooty frooty frooty frooty brin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index          channel  \\\n",
       "253    810  emmymadeinjapan   \n",
       "254    811  emmymadeinjapan   \n",
       "255    814  emmymadeinjapan   \n",
       "256    815  emmymadeinjapan   \n",
       "257    836  emmymadeinjapan   \n",
       "\n",
       "                                                 title     video_id  \\\n",
       "253                         WINNERS Curry Set Giveaway  CQTp_Hh8qH4   \n",
       "254                               PEZ giveaway WINNERS  stpWXStiw4k   \n",
       "255                             PEZ Whatcha Eating #82  yJfm6wFnr2s   \n",
       "256  Gummy Burger Set - Lunch Bag: Whatcha Eating? #81  9cbb_kdUspU   \n",
       "257              Giveaway Winners - Chocolat de Tomato  R-VvqR0EFNk   \n",
       "\n",
       "                                           description  \\\n",
       "253  Announcing the winners of the Popin Cookin' Ka...   \n",
       "254  Watch to find out if you're one of the lucky w...   \n",
       "255  [GIVEAWAY CLOSED] Eating old fashioned PEZ can...   \n",
       "256  [GIVEAWAY CLOSED] A miniature gummy version of...   \n",
       "257  Wanna try Japanese tomato chocolate for yourse...   \n",
       "\n",
       "                                              captions sponsored  \\\n",
       "253  1\\n00:00:06,680 --> 00:00:11,519\\nhi everyone ...        no   \n",
       "254  1\\n00:00:08,540 --> 00:00:13,200\\nhello everyb...        no   \n",
       "255  1\\n00:00:08,470 --> 00:00:15,980\\nhello everyb...        no   \n",
       "256  1\\n00:00:07,910 --> 00:00:14,639\\nhi everybody...        no   \n",
       "257  1\\n00:00:07,280 --> 00:00:12,870\\nhello you tw...        no   \n",
       "\n",
       "                                          fullCaptions  \n",
       "253  grins uglies hides and we welcome back to anot...  \n",
       "254  hello everybody I'm back again and it's it's s...  \n",
       "255  greetings my lovelies hi and welcome back to a...  \n",
       "256  everybody it's a me and I'm back and I'm still...  \n",
       "257  frooty frooty frooty frooty frooty frooty brin...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbname = 'youtubeSpon'\n",
    "username = 'april' # change this to your username\n",
    "\n",
    "engine = create_engine('postgres://%s@localhost/%s'%(username,dbname))\n",
    "con = None\n",
    "con = psycopg2.connect(database = dbname, user = username)\n",
    "# query:\n",
    "sql_query = \"\"\"\n",
    "SELECT * FROM \"youtubeEmmy\" WHERE sponsored <> 'None';\n",
    "\"\"\"\n",
    "youtube_data_from_sql = pd.read_sql_query(sql_query,con)\n",
    "youtube_data_from_sql.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_with_captions= pd.read_pickle(\"emmy.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_size = 15\n",
    "not_spon = [index for index, item in enumerate(youtube_data_from_sql.sponsored) if item == 'no']\n",
    "not_spon_sample = random.sample(not_spon,sample_size)\n",
    "spon = [index for index, item in enumerate(youtube_data_from_sql.sponsored) if item == 'yes']\n",
    "spon_sample = random.sample(spon,sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>channel</th>\n",
       "      <th>title</th>\n",
       "      <th>video_id</th>\n",
       "      <th>description</th>\n",
       "      <th>captions</th>\n",
       "      <th>sponsored</th>\n",
       "      <th>fullCaptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>CHECKERBOARD Pan TEST Gatorade Cake Recipe | D...</td>\n",
       "      <td>SsFO-NvMcNs</td>\n",
       "      <td>This set of pans promises to make a triple lay...</td>\n",
       "      <td>1\\n00:00:06,100 --&gt; 00:00:09,179\\nGreetings my...</td>\n",
       "      <td>no</td>\n",
       "      <td>Happy Holidays lovelies hi it's Emmy and welco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>139</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>GLUE GUN &amp; CHEESE | DIY Fondoodler | extrude m...</td>\n",
       "      <td>2w5W1t4gOC0</td>\n",
       "      <td>Today we're answering the age old question, Wh...</td>\n",
       "      <td>1\\n00:00:04,529 --&gt; 00:00:09,210\\ncreated my l...</td>\n",
       "      <td>no</td>\n",
       "      <td>greetings YouTube hi it's Emmy I'm back this t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>68</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>EGGSTRACTOR egg peeling gadget | Does it Work?</td>\n",
       "      <td>jvYxlbIGlxw</td>\n",
       "      <td>It's supposed to simplify your life by making ...</td>\n",
       "      <td>1\\n00:00:06,220 --&gt; 00:00:09,892\\nGreetings my...</td>\n",
       "      <td>no</td>\n",
       "      <td>Greetings my lovelies! Hi, it's Emmy -- welcom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>80</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>OMATSURI POPIN' COOKIN' Japanese Candy Kit mak...</td>\n",
       "      <td>356nKRf9lBA</td>\n",
       "      <td>Summers in Japan means matsuri, summertime fes...</td>\n",
       "      <td>1\\n00:00:04,160 --&gt; 00:00:08,730\\ngreetings my...</td>\n",
       "      <td>no</td>\n",
       "      <td>greetings uglies hi it's Emmy welcome back to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>706</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>Emmy Eats China - tasting Chinese sweets</td>\n",
       "      <td>mmsAWGJmF-E</td>\n",
       "      <td>Sampling a bit of the China, including some Mi...</td>\n",
       "      <td>1\\n00:00:07,490 --&gt; 00:00:14,219\\nhi lovelies ...</td>\n",
       "      <td>no</td>\n",
       "      <td>Greetings my lovelies! Hi, it's Emmy, and welc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>124</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>Trader Joe's KNOCK-OFF Candy Bar TASTE TEST | ...</td>\n",
       "      <td>MK_wNXdIDd8</td>\n",
       "      <td>Trader Joe's has a couple of candy bars that s...</td>\n",
       "      <td>1\\n00:00:01,740 --&gt; 00:00:04,930\\n[Music]\\n\\n2...</td>\n",
       "      <td>no</td>\n",
       "      <td>[A Mission music] Greetings my beautiful lovel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>53</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>Cooking a Whole BLACK Silkie CHICKEN in a PUMP...</td>\n",
       "      <td>_nxFjhcyTMQ</td>\n",
       "      <td>Black Silkie Chinese herbal chicken soup is a ...</td>\n",
       "      <td>1\\n00:00:00,000 --&gt; 00:00:05,560\\n[Music]\\n\\n2...</td>\n",
       "      <td>no</td>\n",
       "      <td>[Music] greetings my lovelies hi it's Emmy wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>254</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>Japanese OREO Taste Test - Whatcha Eating?</td>\n",
       "      <td>lf5aDczijKQ</td>\n",
       "      <td>Tasting Japanese Oreo varieties on this Emmyma...</td>\n",
       "      <td>1\\n00:00:06,220 --&gt; 00:00:07,360\\nHello, my be...</td>\n",
       "      <td>no</td>\n",
       "      <td>greetings my lovelies hi it's I mean welcome b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>47</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>Kitty Litter CAKE | Dollar $tore Recipe</td>\n",
       "      <td>M3ooQjM2OUA</td>\n",
       "      <td>This kitty litter cake's repulsiveness is only...</td>\n",
       "      <td>1\\n00:00:01,860 --&gt; 00:00:05,439\\n[Music]\\n\\n2...</td>\n",
       "      <td>no</td>\n",
       "      <td>Grimm's always hides I mean welcome back to te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>144</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>BIGMAC VS WHOPPER | Versus BURGER edition</td>\n",
       "      <td>UYNfrhspW0A</td>\n",
       "      <td>A classic burger battle: McDonald's Big Mac v....</td>\n",
       "      <td>1\\n00:00:00,660 --&gt; 00:00:08,160\\n[Music]\\n\\n2...</td>\n",
       "      <td>no</td>\n",
       "      <td>[Music] greetings my lovelies hi and we welcom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>65</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>💥Popin' Cookin' Okosama KID'S Lunch -💥 popping...</td>\n",
       "      <td>AxDjZRaLAfU</td>\n",
       "      <td>This candy kit makes a miniature version of a ...</td>\n",
       "      <td>1\\n00:00:00,170 --&gt; 00:00:02,599\\n[Music]\\n\\n2...</td>\n",
       "      <td>no</td>\n",
       "      <td>greetings my lovelies highs and we welcome bac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>187</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>CHEETOS Cookie Taste Test - COOKIE GOOD</td>\n",
       "      <td>MsUg1x3ufe8</td>\n",
       "      <td>On my last trip to California I stopped into C...</td>\n",
       "      <td>1\\n00:00:00,000 --&gt; 00:00:02,840\\n[Music]\\n\\n2...</td>\n",
       "      <td>no</td>\n",
       "      <td>Greetings lovelies! Hi, it's Emmy! Welcome bac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>54</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>Giant OREO APPLE PIE CAKE - apple pies INSIDE ...</td>\n",
       "      <td>2_RhQnKNG90</td>\n",
       "      <td>Inspired by the infamous Cherpumple – the Gian...</td>\n",
       "      <td>1\\n00:00:06,339 --&gt; 00:00:08,819\\nGreetings my...</td>\n",
       "      <td>no</td>\n",
       "      <td>greetings YouTube it's ME ME back any from an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>234</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>SPAM Taste Test - 6 Flavors</td>\n",
       "      <td>aw--JXL5eKM</td>\n",
       "      <td>SPAM meat in a can.  Did you know that it come...</td>\n",
       "      <td>1\\n00:00:05,930 --&gt; 00:00:09,780\\ngreetings my...</td>\n",
       "      <td>no</td>\n",
       "      <td>greetings my lovelies hi welcome back to anoth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>246</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>Lay's Global Flavors Potato Chips Taste Test -...</td>\n",
       "      <td>qe2UATK5eQs</td>\n",
       "      <td>Tasting some unique Lay’s potato chip flavors ...</td>\n",
       "      <td>1\\n00:00:05,000 --&gt; 00:00:08,980\\nHello my lov...</td>\n",
       "      <td>no</td>\n",
       "      <td>hello my lovelies it's Emmy welcome back today...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>297</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>Flo Braker's Pain d'amande</td>\n",
       "      <td>69YE1Yx2lSA</td>\n",
       "      <td>This is one of the best cookie recipes ever.  ...</td>\n",
       "      <td>1\\n00:00:06,280 --&gt; 00:00:08,000\\nGreetings my...</td>\n",
       "      <td>yes</td>\n",
       "      <td>greetings everyone its Emily hi I am back to e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>107</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>Chopping MINI Veggie GUMMY Making Kit | TonTon...</td>\n",
       "      <td>2NygsfTkxCw</td>\n",
       "      <td>Visit https://squarespace.com/emmy and enter t...</td>\n",
       "      <td>1\\n00:00:00,310 --&gt; 00:00:07,680\\n[Music]\\n\\n2...</td>\n",
       "      <td>yes</td>\n",
       "      <td>Greetings my lovelies! Hi it's Emmy. Welcome b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>94</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>SUSHI BAZOOKA Sushezi sushi maker | Does it Work?</td>\n",
       "      <td>Sojf2kS6Po8</td>\n",
       "      <td>Go to https://thoughtfully.com/emmy and use th...</td>\n",
       "      <td>1\\n00:00:00,130 --&gt; 00:00:08,099\\n[Music]\\n\\n2...</td>\n",
       "      <td>yes</td>\n",
       "      <td>hi everyone it's an Emmy I'm back to announce ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>33</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>Emmy REACTS To Her 1st VIDEO | My 7-year YouTu...</td>\n",
       "      <td>BztZKL8BScY</td>\n",
       "      <td>This video IS sponsored by Best Fiends.  Click...</td>\n",
       "      <td>1\\n00:00:00,000 --&gt; 00:00:02,540\\n[Music]\\n\\n2...</td>\n",
       "      <td>yes</td>\n",
       "      <td>greetings lovely people it's Emily and I am ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>41</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>What My KIDS Eat in a Week Part 2</td>\n",
       "      <td>OU6eqMtTQCw</td>\n",
       "      <td>Check out HELLO FRESH: http://bit.ly/2fiQBC0 a...</td>\n",
       "      <td>1\\n00:00:03,740 --&gt; 00:00:07,440\\ngreetings my...</td>\n",
       "      <td>yes</td>\n",
       "      <td>drinks my lovelies highs I mean welcome back t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>45</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>Thai Spicy Wing Challenge</td>\n",
       "      <td>6DTC9htPQ18</td>\n",
       "      <td>Click here http://bit.ly/2l1c2wJ to receive $7...</td>\n",
       "      <td>1\\n00:00:00,860 --&gt; 00:00:09,300\\n[Music]\\n\\n2...</td>\n",
       "      <td>yes</td>\n",
       "      <td>in science meets today of the state and it is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>103</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>Chinese Take-Out TASTE TEST | my first time or...</td>\n",
       "      <td>QDlbOrOO0_E</td>\n",
       "      <td>Click here http://bit.ly/2suCPnr to receive a ...</td>\n",
       "      <td>1\\n00:00:00,000 --&gt; 00:00:02,790\\n[Music]\\n\\n2...</td>\n",
       "      <td>yes</td>\n",
       "      <td>hi everyone its Amy I'm back to eat some candy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>57</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>What Emmy Eats in a Week #6</td>\n",
       "      <td>SHobkpQ9GOM</td>\n",
       "      <td>Check out HELLO FRESH: http://bit.ly/2fiQBC0 a...</td>\n",
       "      <td>1\\n00:00:00,000 --&gt; 00:00:02,180\\n[Music]\\n\\n2...</td>\n",
       "      <td>yes</td>\n",
       "      <td>greetings my beautiful lovely how are you I ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>222</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>DIY Sushi Burrito</td>\n",
       "      <td>v1AityOKvAw</td>\n",
       "      <td>Thanks, Candid for sponsoring this video! Find...</td>\n",
       "      <td>1\\n00:00:05,930 --&gt; 00:00:09,630\\ngreetings my...</td>\n",
       "      <td>yes</td>\n",
       "      <td>ah greetings my beautiful lovelies Hyatts and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>207</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>Simplest Mulligatawny Soup | Indian-style Curr...</td>\n",
       "      <td>uXJnrJglmy4</td>\n",
       "      <td>A big thank you to Progresso for sponsoring th...</td>\n",
       "      <td>1\\n00:00:00,260 --&gt; 00:00:04,060\\n[Music]\\n\\n2...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[Music] reading with my lovely science and wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>29</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>BURGER Menu Taste Test</td>\n",
       "      <td>jPkRGHivRD8</td>\n",
       "      <td>Click here http://bit.ly/2l1c2wJ to receive $7...</td>\n",
       "      <td>1\\n00:00:03,780 --&gt; 00:00:05,280\\nGreetings my...</td>\n",
       "      <td>yes</td>\n",
       "      <td>Greetings my beautiful lovelies! Hi, it's Emmy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>208</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>Simplest Ohno no Khao Swe | Burmese-style Coco...</td>\n",
       "      <td>5eJNb_0e1zk</td>\n",
       "      <td>Big thanks to Progresso for sponsoring this vi...</td>\n",
       "      <td>1\\n00:00:00,110 --&gt; 00:00:02,569\\n[Music]\\n\\n2...</td>\n",
       "      <td>yes</td>\n",
       "      <td>frooty frooty frooty frooty frooty frooty froo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>101</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>KOREAN CHEETOS Taste Test</td>\n",
       "      <td>yORcJPXKWp4</td>\n",
       "      <td>Visit https://squarespace.com/emmy and enter t...</td>\n",
       "      <td>1\\n00:00:00,090 --&gt; 00:00:07,740\\n[Music]\\n\\n2...</td>\n",
       "      <td>yes</td>\n",
       "      <td>hi everyone I'm back and today I am back with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>105</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>The HOTDOGGER | 1970s hot dog electrocutor | D...</td>\n",
       "      <td>dTG0veHngoM</td>\n",
       "      <td>Sign up to GlassesUSA.com for 50% off + free s...</td>\n",
       "      <td>1\\n00:00:01,780 --&gt; 00:00:07,230\\n[Music]\\n\\n2...</td>\n",
       "      <td>yes</td>\n",
       "      <td>greetings my lovelies hi it's I mean welcome b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>119</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>3 EDIBLE Experiments Jikken Neruneru | Japanes...</td>\n",
       "      <td>0_AbvS-yU4c</td>\n",
       "      <td>Visit https://squarespace.com/emmy and enter t...</td>\n",
       "      <td>1\\n00:00:00,060 --&gt; 00:00:02,170\\n[Music]\\n\\n2...</td>\n",
       "      <td>yes</td>\n",
       "      <td>greetings lovelies hi and welcome back to anot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index          channel  \\\n",
       "3        4  emmymadeinjapan   \n",
       "121    139  emmymadeinjapan   \n",
       "53      68  emmymadeinjapan   \n",
       "64      80  emmymadeinjapan   \n",
       "250    706  emmymadeinjapan   \n",
       "106    124  emmymadeinjapan   \n",
       "41      53  emmymadeinjapan   \n",
       "234    254  emmymadeinjapan   \n",
       "35      47  emmymadeinjapan   \n",
       "127    144  emmymadeinjapan   \n",
       "50      65  emmymadeinjapan   \n",
       "169    187  emmymadeinjapan   \n",
       "42      54  emmymadeinjapan   \n",
       "214    234  emmymadeinjapan   \n",
       "226    246  emmymadeinjapan   \n",
       "243    297  emmymadeinjapan   \n",
       "89     107  emmymadeinjapan   \n",
       "77      94  emmymadeinjapan   \n",
       "30      33  emmymadeinjapan   \n",
       "31      41  emmymadeinjapan   \n",
       "33      45  emmymadeinjapan   \n",
       "86     103  emmymadeinjapan   \n",
       "44      57  emmymadeinjapan   \n",
       "203    222  emmymadeinjapan   \n",
       "188    207  emmymadeinjapan   \n",
       "27      29  emmymadeinjapan   \n",
       "189    208  emmymadeinjapan   \n",
       "84     101  emmymadeinjapan   \n",
       "88     105  emmymadeinjapan   \n",
       "101    119  emmymadeinjapan   \n",
       "\n",
       "                                                 title     video_id  \\\n",
       "3    CHECKERBOARD Pan TEST Gatorade Cake Recipe | D...  SsFO-NvMcNs   \n",
       "121  GLUE GUN & CHEESE | DIY Fondoodler | extrude m...  2w5W1t4gOC0   \n",
       "53      EGGSTRACTOR egg peeling gadget | Does it Work?  jvYxlbIGlxw   \n",
       "64   OMATSURI POPIN' COOKIN' Japanese Candy Kit mak...  356nKRf9lBA   \n",
       "250           Emmy Eats China - tasting Chinese sweets  mmsAWGJmF-E   \n",
       "106  Trader Joe's KNOCK-OFF Candy Bar TASTE TEST | ...  MK_wNXdIDd8   \n",
       "41   Cooking a Whole BLACK Silkie CHICKEN in a PUMP...  _nxFjhcyTMQ   \n",
       "234         Japanese OREO Taste Test - Whatcha Eating?  lf5aDczijKQ   \n",
       "35             Kitty Litter CAKE | Dollar $tore Recipe  M3ooQjM2OUA   \n",
       "127          BIGMAC VS WHOPPER | Versus BURGER edition  UYNfrhspW0A   \n",
       "50   💥Popin' Cookin' Okosama KID'S Lunch -💥 popping...  AxDjZRaLAfU   \n",
       "169            CHEETOS Cookie Taste Test - COOKIE GOOD  MsUg1x3ufe8   \n",
       "42   Giant OREO APPLE PIE CAKE - apple pies INSIDE ...  2_RhQnKNG90   \n",
       "214                        SPAM Taste Test - 6 Flavors  aw--JXL5eKM   \n",
       "226  Lay's Global Flavors Potato Chips Taste Test -...  qe2UATK5eQs   \n",
       "243                         Flo Braker's Pain d'amande  69YE1Yx2lSA   \n",
       "89   Chopping MINI Veggie GUMMY Making Kit | TonTon...  2NygsfTkxCw   \n",
       "77   SUSHI BAZOOKA Sushezi sushi maker | Does it Work?  Sojf2kS6Po8   \n",
       "30   Emmy REACTS To Her 1st VIDEO | My 7-year YouTu...  BztZKL8BScY   \n",
       "31                   What My KIDS Eat in a Week Part 2  OU6eqMtTQCw   \n",
       "33                           Thai Spicy Wing Challenge  6DTC9htPQ18   \n",
       "86   Chinese Take-Out TASTE TEST | my first time or...  QDlbOrOO0_E   \n",
       "44                         What Emmy Eats in a Week #6  SHobkpQ9GOM   \n",
       "203                                  DIY Sushi Burrito  v1AityOKvAw   \n",
       "188  Simplest Mulligatawny Soup | Indian-style Curr...  uXJnrJglmy4   \n",
       "27                              BURGER Menu Taste Test  jPkRGHivRD8   \n",
       "189  Simplest Ohno no Khao Swe | Burmese-style Coco...  5eJNb_0e1zk   \n",
       "84                           KOREAN CHEETOS Taste Test  yORcJPXKWp4   \n",
       "88   The HOTDOGGER | 1970s hot dog electrocutor | D...  dTG0veHngoM   \n",
       "101  3 EDIBLE Experiments Jikken Neruneru | Japanes...  0_AbvS-yU4c   \n",
       "\n",
       "                                           description  \\\n",
       "3    This set of pans promises to make a triple lay...   \n",
       "121  Today we're answering the age old question, Wh...   \n",
       "53   It's supposed to simplify your life by making ...   \n",
       "64   Summers in Japan means matsuri, summertime fes...   \n",
       "250  Sampling a bit of the China, including some Mi...   \n",
       "106  Trader Joe's has a couple of candy bars that s...   \n",
       "41   Black Silkie Chinese herbal chicken soup is a ...   \n",
       "234  Tasting Japanese Oreo varieties on this Emmyma...   \n",
       "35   This kitty litter cake's repulsiveness is only...   \n",
       "127  A classic burger battle: McDonald's Big Mac v....   \n",
       "50   This candy kit makes a miniature version of a ...   \n",
       "169  On my last trip to California I stopped into C...   \n",
       "42   Inspired by the infamous Cherpumple – the Gian...   \n",
       "214  SPAM meat in a can.  Did you know that it come...   \n",
       "226  Tasting some unique Lay’s potato chip flavors ...   \n",
       "243  This is one of the best cookie recipes ever.  ...   \n",
       "89   Visit https://squarespace.com/emmy and enter t...   \n",
       "77   Go to https://thoughtfully.com/emmy and use th...   \n",
       "30   This video IS sponsored by Best Fiends.  Click...   \n",
       "31   Check out HELLO FRESH: http://bit.ly/2fiQBC0 a...   \n",
       "33   Click here http://bit.ly/2l1c2wJ to receive $7...   \n",
       "86   Click here http://bit.ly/2suCPnr to receive a ...   \n",
       "44   Check out HELLO FRESH: http://bit.ly/2fiQBC0 a...   \n",
       "203  Thanks, Candid for sponsoring this video! Find...   \n",
       "188  A big thank you to Progresso for sponsoring th...   \n",
       "27   Click here http://bit.ly/2l1c2wJ to receive $7...   \n",
       "189  Big thanks to Progresso for sponsoring this vi...   \n",
       "84   Visit https://squarespace.com/emmy and enter t...   \n",
       "88   Sign up to GlassesUSA.com for 50% off + free s...   \n",
       "101  Visit https://squarespace.com/emmy and enter t...   \n",
       "\n",
       "                                              captions sponsored  \\\n",
       "3    1\\n00:00:06,100 --> 00:00:09,179\\nGreetings my...        no   \n",
       "121  1\\n00:00:04,529 --> 00:00:09,210\\ncreated my l...        no   \n",
       "53   1\\n00:00:06,220 --> 00:00:09,892\\nGreetings my...        no   \n",
       "64   1\\n00:00:04,160 --> 00:00:08,730\\ngreetings my...        no   \n",
       "250  1\\n00:00:07,490 --> 00:00:14,219\\nhi lovelies ...        no   \n",
       "106  1\\n00:00:01,740 --> 00:00:04,930\\n[Music]\\n\\n2...        no   \n",
       "41   1\\n00:00:00,000 --> 00:00:05,560\\n[Music]\\n\\n2...        no   \n",
       "234  1\\n00:00:06,220 --> 00:00:07,360\\nHello, my be...        no   \n",
       "35   1\\n00:00:01,860 --> 00:00:05,439\\n[Music]\\n\\n2...        no   \n",
       "127  1\\n00:00:00,660 --> 00:00:08,160\\n[Music]\\n\\n2...        no   \n",
       "50   1\\n00:00:00,170 --> 00:00:02,599\\n[Music]\\n\\n2...        no   \n",
       "169  1\\n00:00:00,000 --> 00:00:02,840\\n[Music]\\n\\n2...        no   \n",
       "42   1\\n00:00:06,339 --> 00:00:08,819\\nGreetings my...        no   \n",
       "214  1\\n00:00:05,930 --> 00:00:09,780\\ngreetings my...        no   \n",
       "226  1\\n00:00:05,000 --> 00:00:08,980\\nHello my lov...        no   \n",
       "243  1\\n00:00:06,280 --> 00:00:08,000\\nGreetings my...       yes   \n",
       "89   1\\n00:00:00,310 --> 00:00:07,680\\n[Music]\\n\\n2...       yes   \n",
       "77   1\\n00:00:00,130 --> 00:00:08,099\\n[Music]\\n\\n2...       yes   \n",
       "30   1\\n00:00:00,000 --> 00:00:02,540\\n[Music]\\n\\n2...       yes   \n",
       "31   1\\n00:00:03,740 --> 00:00:07,440\\ngreetings my...       yes   \n",
       "33   1\\n00:00:00,860 --> 00:00:09,300\\n[Music]\\n\\n2...       yes   \n",
       "86   1\\n00:00:00,000 --> 00:00:02,790\\n[Music]\\n\\n2...       yes   \n",
       "44   1\\n00:00:00,000 --> 00:00:02,180\\n[Music]\\n\\n2...       yes   \n",
       "203  1\\n00:00:05,930 --> 00:00:09,630\\ngreetings my...       yes   \n",
       "188  1\\n00:00:00,260 --> 00:00:04,060\\n[Music]\\n\\n2...       yes   \n",
       "27   1\\n00:00:03,780 --> 00:00:05,280\\nGreetings my...       yes   \n",
       "189  1\\n00:00:00,110 --> 00:00:02,569\\n[Music]\\n\\n2...       yes   \n",
       "84   1\\n00:00:00,090 --> 00:00:07,740\\n[Music]\\n\\n2...       yes   \n",
       "88   1\\n00:00:01,780 --> 00:00:07,230\\n[Music]\\n\\n2...       yes   \n",
       "101  1\\n00:00:00,060 --> 00:00:02,170\\n[Music]\\n\\n2...       yes   \n",
       "\n",
       "                                          fullCaptions  \n",
       "3    Happy Holidays lovelies hi it's Emmy and welco...  \n",
       "121  greetings YouTube hi it's Emmy I'm back this t...  \n",
       "53   Greetings my lovelies! Hi, it's Emmy -- welcom...  \n",
       "64   greetings uglies hi it's Emmy welcome back to ...  \n",
       "250  Greetings my lovelies! Hi, it's Emmy, and welc...  \n",
       "106  [A Mission music] Greetings my beautiful lovel...  \n",
       "41   [Music] greetings my lovelies hi it's Emmy wel...  \n",
       "234  greetings my lovelies hi it's I mean welcome b...  \n",
       "35   Grimm's always hides I mean welcome back to te...  \n",
       "127  [Music] greetings my lovelies hi and we welcom...  \n",
       "50   greetings my lovelies highs and we welcome bac...  \n",
       "169  Greetings lovelies! Hi, it's Emmy! Welcome bac...  \n",
       "42   greetings YouTube it's ME ME back any from an ...  \n",
       "214  greetings my lovelies hi welcome back to anoth...  \n",
       "226  hello my lovelies it's Emmy welcome back today...  \n",
       "243  greetings everyone its Emily hi I am back to e...  \n",
       "89   Greetings my lovelies! Hi it's Emmy. Welcome b...  \n",
       "77   hi everyone it's an Emmy I'm back to announce ...  \n",
       "30   greetings lovely people it's Emily and I am ba...  \n",
       "31   drinks my lovelies highs I mean welcome back t...  \n",
       "33   in science meets today of the state and it is ...  \n",
       "86   hi everyone its Amy I'm back to eat some candy...  \n",
       "44   greetings my beautiful lovely how are you I ho...  \n",
       "203  ah greetings my beautiful lovelies Hyatts and ...  \n",
       "188  [Music] reading with my lovely science and wel...  \n",
       "27   Greetings my beautiful lovelies! Hi, it's Emmy...  \n",
       "189  frooty frooty frooty frooty frooty frooty froo...  \n",
       "84   hi everyone I'm back and today I am back with ...  \n",
       "88   greetings my lovelies hi it's I mean welcome b...  \n",
       "101  greetings lovelies hi and welcome back to anot...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = youtube_data_from_sql.iloc[not_spon_sample + spon_sample, :]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "stop = stopwords.words('english') + list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tokens = []\n",
    "for sent in train.fullCaptions:\n",
    "    train_tokens.append([i for i in word_tokenize(sent.lower()) if i not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = [y for x in train_tokens for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(w.lower() for w in words)\n",
    "word_features = list(all_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happy',\n",
       " 'holidays',\n",
       " 'lovelies',\n",
       " 'hi',\n",
       " \"'s\",\n",
       " 'emmy',\n",
       " 'welcome',\n",
       " 'back',\n",
       " 'another',\n",
       " 'episode',\n",
       " 'thirsty',\n",
       " 'today',\n",
       " 'couple',\n",
       " 'sodas',\n",
       " \"'m\",\n",
       " 'going',\n",
       " 'try',\n",
       " 'sent',\n",
       " 'company',\n",
       " 'called',\n",
       " 'hot',\n",
       " 'lips',\n",
       " 'boo',\n",
       " 'based',\n",
       " 'portland',\n",
       " 'oregon',\n",
       " 'give',\n",
       " 'opinion',\n",
       " 'thanks',\n",
       " 'outlets',\n",
       " 'maryam/mary',\n",
       " 'sounds',\n",
       " 'delicious',\n",
       " 'looks',\n",
       " 'lot',\n",
       " 'like',\n",
       " 'blackberry',\n",
       " 'raspberry',\n",
       " 'well',\n",
       " 'deliciously',\n",
       " 'refreshing',\n",
       " 'bottle',\n",
       " 'begins',\n",
       " 'fresh',\n",
       " 'picked',\n",
       " 'fruit',\n",
       " 'peak',\n",
       " 'family',\n",
       " 'farms',\n",
       " 'pacific',\n",
       " 'northwest',\n",
       " 'bright',\n",
       " 'juicy',\n",
       " 'all-natural',\n",
       " 'raspberries',\n",
       " 'flecked',\n",
       " 'bits',\n",
       " 'sweet',\n",
       " 'pulp',\n",
       " 'paired',\n",
       " 'soft',\n",
       " 'smooth',\n",
       " 'bubbles',\n",
       " 'good',\n",
       " 'bottles',\n",
       " 'chilled',\n",
       " 'also',\n",
       " 'ice',\n",
       " 'soda',\n",
       " 'ingredients',\n",
       " 'marionberry',\n",
       " 'sandy',\n",
       " 'boring',\n",
       " 'cane',\n",
       " 'sugar',\n",
       " 'organic',\n",
       " 'lawn',\n",
       " 'lemon',\n",
       " 'juice',\n",
       " \"n't\",\n",
       " 'mean',\n",
       " 'insult',\n",
       " 'manners',\n",
       " 'really',\n",
       " 'organ',\n",
       " 'si',\n",
       " 'alright',\n",
       " 'let',\n",
       " 'think',\n",
       " 'type',\n",
       " 'kind',\n",
       " 'hello',\n",
       " 'postal',\n",
       " 'carrier',\n",
       " \"'ve\",\n",
       " 'gotten',\n",
       " 'snow',\n",
       " 'rich',\n",
       " 'doll',\n",
       " 'see',\n",
       " 'every',\n",
       " 'day',\n",
       " 'matter',\n",
       " 'weather',\n",
       " 'reenter',\n",
       " 'shine',\n",
       " 'always',\n",
       " 'wonderful',\n",
       " 'old',\n",
       " 'opener',\n",
       " 'mmm',\n",
       " 'smells',\n",
       " 'lemony',\n",
       " 'pour',\n",
       " 'look',\n",
       " 'beautiful',\n",
       " 'color',\n",
       " 'immediately',\n",
       " 'noticed',\n",
       " 'besides',\n",
       " 'different',\n",
       " 'viscosity',\n",
       " 'typical',\n",
       " 'seems',\n",
       " 'bit',\n",
       " 'thicker',\n",
       " 'marion',\n",
       " 'barry',\n",
       " 'hmm',\n",
       " 'bad',\n",
       " 'lightly',\n",
       " 'fizzy',\n",
       " 'hardly',\n",
       " 'actually',\n",
       " 'phil',\n",
       " 'show',\n",
       " 'camera',\n",
       " 'little',\n",
       " 'definitely',\n",
       " 'higher',\n",
       " 'ratio',\n",
       " 'spritzer',\n",
       " 'odd',\n",
       " 'taste',\n",
       " 'quite',\n",
       " 'expecting',\n",
       " 'hoping',\n",
       " 'would',\n",
       " 'tart',\n",
       " 'tangy',\n",
       " 'punchy',\n",
       " 'pretty',\n",
       " 'almost',\n",
       " 'jammy',\n",
       " 'natural',\n",
       " 'tasting',\n",
       " 'sweeter',\n",
       " 'expected',\n",
       " 'real',\n",
       " 'shake',\n",
       " 'one',\n",
       " 'similar',\n",
       " 'laughs',\n",
       " 'whoo',\n",
       " 'gorgeous',\n",
       " 'come',\n",
       " 'light',\n",
       " 'effervescence',\n",
       " 'flavor',\n",
       " 'artificial',\n",
       " 'drop',\n",
       " 'smell',\n",
       " 'literally',\n",
       " 'metaphorically',\n",
       " 'much',\n",
       " 'flavorings',\n",
       " 'colorings',\n",
       " 'get',\n",
       " 'used',\n",
       " 'stuff',\n",
       " 'reminded',\n",
       " 'max',\n",
       " 'water',\n",
       " 'wish',\n",
       " '10',\n",
       " 'year',\n",
       " 'call',\n",
       " 'clientèle',\n",
       " 'exactly',\n",
       " 'right',\n",
       " 'something',\n",
       " 'tangier',\n",
       " 'punchier',\n",
       " 'maybe',\n",
       " 'assertive',\n",
       " 'drinks',\n",
       " 'whatever',\n",
       " 'drink',\n",
       " 'cases',\n",
       " 'seltzer',\n",
       " 'love',\n",
       " 'even',\n",
       " 'put',\n",
       " 'anything',\n",
       " 'addict',\n",
       " 'two',\n",
       " 'miriam',\n",
       " 'better',\n",
       " \"'re\",\n",
       " 'mood',\n",
       " 'fruity',\n",
       " 'check',\n",
       " 'sending',\n",
       " 'along',\n",
       " 'appreciate',\n",
       " 'thank',\n",
       " 'guys',\n",
       " 'watching',\n",
       " 'hope',\n",
       " 'enjoyed',\n",
       " 'learned',\n",
       " \"'ll\",\n",
       " 'next',\n",
       " 'video',\n",
       " 'lube',\n",
       " 'tears',\n",
       " 'frugal',\n",
       " 'lives',\n",
       " 'surprising',\n",
       " 'medieval',\n",
       " 'days',\n",
       " 'people',\n",
       " 'thought',\n",
       " 'flies',\n",
       " 'maggots',\n",
       " 'spontaneously',\n",
       " 'generated',\n",
       " 'heck',\n",
       " 'eggs',\n",
       " 'sitting',\n",
       " 'bananas',\n",
       " 'strawberries',\n",
       " 'gross',\n",
       " 'guess',\n",
       " 'protein',\n",
       " 'greetings',\n",
       " 'youtube',\n",
       " 'time',\n",
       " 'candy',\n",
       " 'started',\n",
       " 'quick',\n",
       " 'um',\n",
       " 'tutorial',\n",
       " 'want',\n",
       " 'make',\n",
       " 'furoshiki',\n",
       " 'comes',\n",
       " 'word',\n",
       " 'food',\n",
       " 'oh',\n",
       " 'means',\n",
       " 'cheeky',\n",
       " 'sure',\n",
       " 'wrapping',\n",
       " 'tradition',\n",
       " 'carry',\n",
       " 'things',\n",
       " 'zen',\n",
       " 'bathhouse',\n",
       " 'modern',\n",
       " 'plumbing',\n",
       " 'go',\n",
       " 'bath',\n",
       " 'houses',\n",
       " 'unsend',\n",
       " 'spring',\n",
       " 'fed',\n",
       " 'communally',\n",
       " 'bathe',\n",
       " 'makes',\n",
       " 'sense',\n",
       " 'change',\n",
       " 'clothes',\n",
       " 'towel',\n",
       " 'large',\n",
       " 'squares',\n",
       " 'cloth',\n",
       " 'tie',\n",
       " 'bundle',\n",
       " 'create',\n",
       " 'bag',\n",
       " 'carrying',\n",
       " 'container',\n",
       " 'fiduciary',\n",
       " 'permutations',\n",
       " 'kinds',\n",
       " 'bags',\n",
       " 'bento',\n",
       " 'wraps',\n",
       " 'ways',\n",
       " 'tying',\n",
       " 'square',\n",
       " 'piece',\n",
       " 'knots',\n",
       " 'top',\n",
       " 'inside',\n",
       " 'sling',\n",
       " 'wear',\n",
       " 'need',\n",
       " 'big',\n",
       " 'special',\n",
       " 'online',\n",
       " 'find',\n",
       " 'could',\n",
       " 'fabric',\n",
       " 'store',\n",
       " 'hem',\n",
       " 'edges',\n",
       " 'fray',\n",
       " 'use',\n",
       " 'lightweight',\n",
       " 'cotton',\n",
       " 'took',\n",
       " 'saying',\n",
       " 'polyester',\n",
       " 'smaller',\n",
       " 'lunch',\n",
       " 'box',\n",
       " 'handkerchief',\n",
       " 'turn',\n",
       " 'side',\n",
       " 'facing',\n",
       " 'take',\n",
       " 'corner',\n",
       " 'okay',\n",
       " 'triangle',\n",
       " 'draw',\n",
       " 'till',\n",
       " 'halfway',\n",
       " 'simple',\n",
       " 'knot',\n",
       " 'loop',\n",
       " 'around',\n",
       " 'pull',\n",
       " 'far',\n",
       " 'ear',\n",
       " 'thing',\n",
       " 'hand',\n",
       " 'sides',\n",
       " 'nuts',\n",
       " 'important',\n",
       " 'length',\n",
       " 'longer',\n",
       " 'shorter',\n",
       " 'open',\n",
       " 'flaps',\n",
       " 'lift',\n",
       " 'corners',\n",
       " 'essentially',\n",
       " 'proper',\n",
       " 'way',\n",
       " 'cool',\n",
       " 'grass',\n",
       " 'left',\n",
       " 'front',\n",
       " 'twist',\n",
       " 'tighten',\n",
       " 'know',\n",
       " 'done',\n",
       " 'correctly',\n",
       " 'ears',\n",
       " 'horizontal',\n",
       " 'completely',\n",
       " 'parallel',\n",
       " 'incorrectly',\n",
       " 'diesel',\n",
       " 'perpendicular',\n",
       " 'easily',\n",
       " 'untied',\n",
       " 'yank',\n",
       " 'slide',\n",
       " 'untie',\n",
       " 'version',\n",
       " 'cute',\n",
       " 'rags',\n",
       " 'charming',\n",
       " 'interested',\n",
       " 'seeing',\n",
       " 'ones',\n",
       " 'others',\n",
       " 'lunchboxes',\n",
       " 'yeah',\n",
       " 'wine',\n",
       " 'found',\n",
       " 'useful',\n",
       " 'ishiki',\n",
       " 'lesson',\n",
       " 'soon',\n",
       " 'care',\n",
       " 'bye',\n",
       " '--',\n",
       " 'danish',\n",
       " '...',\n",
       " 'kringle',\n",
       " 'last',\n",
       " 'trader',\n",
       " 'joe',\n",
       " 'charmed',\n",
       " 'packaging',\n",
       " 'waxed',\n",
       " 'paper',\n",
       " 'viking',\n",
       " 'name',\n",
       " 'olaf',\n",
       " 'baked',\n",
       " 'daily',\n",
       " '``',\n",
       " \"''\",\n",
       " 'christmas-y',\n",
       " 'anyways',\n",
       " 'bought',\n",
       " '7.00',\n",
       " 'cheap',\n",
       " 'size',\n",
       " 'racine',\n",
       " 'wisconsin',\n",
       " 'bakery',\n",
       " 'says',\n",
       " 'pecan',\n",
       " 'videos',\n",
       " 'forget',\n",
       " 'subscribe',\n",
       " 'tuck',\n",
       " 'gon',\n",
       " 'na',\n",
       " 'cut',\n",
       " 'gosh',\n",
       " 'huge',\n",
       " 'established',\n",
       " '1949',\n",
       " 'christian',\n",
       " 'olesen',\n",
       " 'remains',\n",
       " 'true',\n",
       " 'traditions',\n",
       " 'baking',\n",
       " 'skills',\n",
       " 'originated',\n",
       " 'denmark',\n",
       " 'super',\n",
       " 'envelope',\n",
       " 'plastic',\n",
       " 'ah',\n",
       " 'research',\n",
       " 'prior',\n",
       " 'spoil',\n",
       " 'reaction',\n",
       " 'might',\n",
       " 'original',\n",
       " 'certainly',\n",
       " 'enough',\n",
       " 'feed',\n",
       " 'army',\n",
       " 'round',\n",
       " 'shape',\n",
       " 'phenomenal',\n",
       " 'pecans',\n",
       " 'already',\n",
       " 'filling',\n",
       " 'icing',\n",
       " 'friends',\n",
       " 'say',\n",
       " 'bon',\n",
       " 'appetit',\n",
       " 'comments',\n",
       " 'iitadakimasu',\n",
       " 'pastry',\n",
       " 'flaky',\n",
       " 'tender',\n",
       " 'tons',\n",
       " 'pe-cahns',\n",
       " 'pee-cans',\n",
       " 'however',\n",
       " 'pronounce',\n",
       " 'crunchy',\n",
       " 'salt',\n",
       " 'great',\n",
       " 'balance',\n",
       " 'salty',\n",
       " 'amazing',\n",
       " 'yum',\n",
       " 'dying',\n",
       " 'dip',\n",
       " 'coffee',\n",
       " 'looking',\n",
       " 'breakfast',\n",
       " 'highly',\n",
       " 'recommend',\n",
       " 'picking',\n",
       " 'treat',\n",
       " 'feeds',\n",
       " 'work',\n",
       " 'ask',\n",
       " 'recipe',\n",
       " 'learn',\n",
       " 'comment',\n",
       " 'shall',\n",
       " 'toodeloo',\n",
       " 'hmmm',\n",
       " 'jordy',\n",
       " 'uglies',\n",
       " 'news',\n",
       " 'eating',\n",
       " 'country',\n",
       " 'orb',\n",
       " 'operation',\n",
       " 'ration',\n",
       " 'pack',\n",
       " 'orpah',\n",
       " 'uk',\n",
       " 'viewer',\n",
       " 'named',\n",
       " 'harold',\n",
       " 'amongst',\n",
       " 'excited',\n",
       " 'response',\n",
       " 'mre',\n",
       " 'seen',\n",
       " 'link',\n",
       " 'description',\n",
       " 'acronym',\n",
       " 'meal',\n",
       " 'ready',\n",
       " 'eat',\n",
       " 'packaged',\n",
       " 'cooked',\n",
       " 'troops',\n",
       " 'orc',\n",
       " '24-hour',\n",
       " 'man',\n",
       " '24',\n",
       " 'hours',\n",
       " '7',\n",
       " 'lucky',\n",
       " 'number',\n",
       " 'contained',\n",
       " 'minimum',\n",
       " '4,000',\n",
       " 'kilocalories',\n",
       " 'holy',\n",
       " 'cow',\n",
       " 'gives',\n",
       " 'various',\n",
       " 'heating',\n",
       " 'instructions',\n",
       " 'included',\n",
       " 'nice',\n",
       " 'note',\n",
       " 'said',\n",
       " 'unlike',\n",
       " 'us',\n",
       " 'self',\n",
       " 'pact',\n",
       " 'usually',\n",
       " 'small',\n",
       " 'stove',\n",
       " 'calls',\n",
       " 'hexamine',\n",
       " 'recommended',\n",
       " 'boiled',\n",
       " 'pots',\n",
       " 'kitchen',\n",
       " 'got',\n",
       " 'packs',\n",
       " 'boiling',\n",
       " 'cold',\n",
       " 'feel',\n",
       " 'fair',\n",
       " 'assessment',\n",
       " 'contents',\n",
       " 'package',\n",
       " 'four',\n",
       " 'contain',\n",
       " 'puree',\n",
       " 'apricot',\n",
       " 'cactus',\n",
       " 'spar',\n",
       " 'bar',\n",
       " 'justice',\n",
       " 'beverage',\n",
       " 'whitener',\n",
       " 'teeth',\n",
       " 'waiting',\n",
       " 'main',\n",
       " 'meals',\n",
       " 'heat',\n",
       " 'snacks',\n",
       " 'first',\n",
       " 'castis',\n",
       " 'assuming',\n",
       " 'dried',\n",
       " 'rather',\n",
       " 'dark',\n",
       " 'texture',\n",
       " 'chewy',\n",
       " 'leather',\n",
       " 'overly',\n",
       " 'apricots',\n",
       " 'chopped',\n",
       " 'brazen',\n",
       " 'passable',\n",
       " 'hiking',\n",
       " 'golden',\n",
       " 'snack',\n",
       " 'several',\n",
       " 'becoming',\n",
       " 'packets',\n",
       " 'black',\n",
       " 'currant',\n",
       " 'cherry',\n",
       " 'electrolyte',\n",
       " 'powder',\n",
       " 'exotic',\n",
       " 'made',\n",
       " 'rumble',\n",
       " 'durian',\n",
       " 'stats',\n",
       " 'dancers',\n",
       " 'pop',\n",
       " 'guesstimate',\n",
       " 'teaspoon',\n",
       " 'peachy',\n",
       " 'stir',\n",
       " 'isotonic',\n",
       " 'sour',\n",
       " 'slightly',\n",
       " 'tastes',\n",
       " 'peach',\n",
       " 'sound',\n",
       " 'attractive',\n",
       " 'thick',\n",
       " 'plain-looking',\n",
       " 'grainy',\n",
       " 'oatmeal',\n",
       " 'digestive',\n",
       " 'biscuits',\n",
       " 'terms',\n",
       " 'leverage',\n",
       " 'toasted',\n",
       " 'cookie',\n",
       " 'vanilla',\n",
       " 'butter',\n",
       " 'dense',\n",
       " 'cooking',\n",
       " 'dipped',\n",
       " 'tea',\n",
       " 'spoon',\n",
       " 'official',\n",
       " 'utensil',\n",
       " 'start',\n",
       " 'starter',\n",
       " 'chicken',\n",
       " 'vegetable',\n",
       " 'soup',\n",
       " 'canteen',\n",
       " 'cafeteria',\n",
       " 'tinned',\n",
       " 'yellowy',\n",
       " 'white',\n",
       " 'chunks',\n",
       " 'carrot',\n",
       " 'moms',\n",
       " 'wow',\n",
       " 'hotter',\n",
       " 'chemical',\n",
       " 'anticipate',\n",
       " 'cream',\n",
       " 'creamy',\n",
       " 'milky',\n",
       " 'celery',\n",
       " 'ooh',\n",
       " 'interesting',\n",
       " 'striking',\n",
       " 'fake',\n",
       " 'red',\n",
       " 'plummet',\n",
       " 'surprised',\n",
       " 'kool-aid',\n",
       " 'though',\n",
       " 'alarming',\n",
       " 'caramels',\n",
       " 'cereal',\n",
       " 'mm-hmm',\n",
       " 'veiled',\n",
       " 'caramely',\n",
       " 'rice',\n",
       " 'akin',\n",
       " 'griddle',\n",
       " 'states',\n",
       " 'pasta',\n",
       " 'mushrooms',\n",
       " 'yes',\n",
       " 'designated',\n",
       " 'tool',\n",
       " 'boil',\n",
       " 'although',\n",
       " 'needs',\n",
       " 'bush',\n",
       " 'options',\n",
       " 'cheesy',\n",
       " 'shell',\n",
       " 'pieces',\n",
       " 'wetter',\n",
       " 'mac',\n",
       " 'cheese',\n",
       " 'sauce',\n",
       " 'forever',\n",
       " 'generally',\n",
       " 'speaking',\n",
       " '2',\n",
       " '1',\n",
       " 'tabasco',\n",
       " 'came',\n",
       " 'packet',\n",
       " 'actual',\n",
       " 'stinking',\n",
       " 'glass',\n",
       " 'teeny-tiny',\n",
       " 'nose',\n",
       " 'tiny',\n",
       " 'screw',\n",
       " 'lid',\n",
       " 'add',\n",
       " 'infinitely',\n",
       " 'pocket',\n",
       " 'yellow',\n",
       " 'cap',\n",
       " 'gilbird',\n",
       " 'deckle',\n",
       " 'apple',\n",
       " 'mango',\n",
       " 'excellent',\n",
       " 'mostly',\n",
       " 'applesauce',\n",
       " 'hint',\n",
       " 'son',\n",
       " 'loves',\n",
       " 'purple',\n",
       " 'lovely',\n",
       " 'blueberry',\n",
       " 'weird',\n",
       " 'chocolate',\n",
       " 'chip',\n",
       " 'boat',\n",
       " 'biscuit',\n",
       " 'soylent',\n",
       " 'green',\n",
       " 'space-age',\n",
       " 'ii',\n",
       " 'five',\n",
       " 'cookies',\n",
       " 'thinner',\n",
       " 'oat',\n",
       " 'spattered',\n",
       " 'clock',\n",
       " 'od',\n",
       " 'dry',\n",
       " 'crisp',\n",
       " 'flecks',\n",
       " 'mix',\n",
       " 'medium',\n",
       " 'wicked',\n",
       " 'fast',\n",
       " 'ever',\n",
       " 'thai',\n",
       " 'teacup',\n",
       " 'steeping',\n",
       " 'swiss',\n",
       " 'miss',\n",
       " 'instant',\n",
       " 'remind',\n",
       " 'child',\n",
       " 'homemade',\n",
       " 'milk',\n",
       " 'ca',\n",
       " 'neither',\n",
       " 'coughing',\n",
       " 'team',\n",
       " 'bitter',\n",
       " 'mmm-hmm',\n",
       " 'matches',\n",
       " 'wet',\n",
       " 'conditions',\n",
       " 'includes',\n",
       " 'striker',\n",
       " 'west',\n",
       " 'wo',\n",
       " 'trying',\n",
       " 'tubes',\n",
       " 'creamer',\n",
       " 'never',\n",
       " 'heard',\n",
       " 'tissues',\n",
       " 'paloma',\n",
       " 'slovenia',\n",
       " 'pudding',\n",
       " 'product',\n",
       " 'house',\n",
       " 'gelatin',\n",
       " 'oftentimes',\n",
       " 'tapioca',\n",
       " 'steamed',\n",
       " 'bread',\n",
       " 'spotted',\n",
       " 'dick',\n",
       " 'imagining',\n",
       " 'divine',\n",
       " 'chocolatey',\n",
       " 'indeed',\n",
       " 'luscious',\n",
       " 'secondary',\n",
       " 'dessert',\n",
       " 'pleasant',\n",
       " 'chocolaty',\n",
       " 'buttery',\n",
       " 'scrumptious',\n",
       " 'according',\n",
       " 'glad',\n",
       " 'decimals',\n",
       " 'strongly',\n",
       " 'polo',\n",
       " 'mints',\n",
       " 'minty',\n",
       " 'lifesaver',\n",
       " 'crumbly',\n",
       " 'less',\n",
       " 'breath',\n",
       " 'freshener',\n",
       " 'almonds',\n",
       " 'peanuts',\n",
       " 'cashews',\n",
       " 'salted',\n",
       " 'reminds',\n",
       " 'german',\n",
       " 'student',\n",
       " 'feta',\n",
       " 'crunch',\n",
       " 'bland',\n",
       " 'unfortunately',\n",
       " '50',\n",
       " 'grams',\n",
       " 'textured',\n",
       " 'granola',\n",
       " 'bars',\n",
       " 'stage',\n",
       " 'consider',\n",
       " 'healthy',\n",
       " 'full',\n",
       " 'chew',\n",
       " 'lots',\n",
       " 'oats',\n",
       " 'sunflower',\n",
       " 'seeds',\n",
       " 'energy',\n",
       " 'maple',\n",
       " 'syrup',\n",
       " 'bun',\n",
       " 'terrible',\n",
       " 'unattractive',\n",
       " 'appetizing',\n",
       " 'bear',\n",
       " 'claw',\n",
       " 'cinnamony',\n",
       " 'artificially',\n",
       " 'sticky',\n",
       " 'cinnamon',\n",
       " 'roll',\n",
       " 'smushed',\n",
       " \"'d\",\n",
       " 'long',\n",
       " 'finish',\n",
       " 'strong',\n",
       " 'mint',\n",
       " 'gum',\n",
       " 'six',\n",
       " 'norway',\n",
       " 'cooley',\n",
       " 'international',\n",
       " 'brand',\n",
       " 'xylitol',\n",
       " 'gums',\n",
       " 'nordic',\n",
       " 'countries',\n",
       " 'slippery',\n",
       " 'hard',\n",
       " 'rubbery',\n",
       " 'quickly',\n",
       " 'alcohol',\n",
       " 'u.s.',\n",
       " 'laxative',\n",
       " 'disclosure',\n",
       " 'issues',\n",
       " 'lighting',\n",
       " 'purifying',\n",
       " 'entire',\n",
       " 'herald',\n",
       " 'presented',\n",
       " 'delight',\n",
       " 'cultural',\n",
       " 'differences',\n",
       " 'similarities',\n",
       " 'tap',\n",
       " 'camping',\n",
       " 'survival',\n",
       " 'instincts',\n",
       " 'tillu',\n",
       " 'internet',\n",
       " 'toddie',\n",
       " 'palm',\n",
       " 'include',\n",
       " 'fridays',\n",
       " 'poetry',\n",
       " 'including',\n",
       " 'date',\n",
       " 'coconut',\n",
       " 'thailand',\n",
       " 'toddy',\n",
       " 'pond',\n",
       " 'alcoholic',\n",
       " 'target',\n",
       " 'practice',\n",
       " 'shooting',\n",
       " 'requested',\n",
       " 'raindrop',\n",
       " 'cake',\n",
       " 'japanese',\n",
       " 'mizu',\n",
       " 'shingen',\n",
       " 'mochi',\n",
       " 'clear',\n",
       " 'jelly',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'friend',\n",
       " 'mosogourmet',\n",
       " 'channel',\n",
       " 'inspiration',\n",
       " 'major',\n",
       " 'tweaks',\n",
       " 'initial',\n",
       " 'fun',\n",
       " 'experimental',\n",
       " 'recipes',\n",
       " \"'makin\",\n",
       " 'ahead',\n",
       " 'saucepan',\n",
       " '450cc',\n",
       " 'filtered',\n",
       " 'gram',\n",
       " 'granulated',\n",
       " 'nicely',\n",
       " 'dissolved',\n",
       " 'onto',\n",
       " 'solution',\n",
       " 'sprinkle',\n",
       " 'agar',\n",
       " 'telephone',\n",
       " 'local',\n",
       " 'asian',\n",
       " 'market',\n",
       " 'medium-high',\n",
       " 'warm',\n",
       " 'dissolves',\n",
       " 'wan',\n",
       " 'many',\n",
       " 'swirl',\n",
       " 'pan',\n",
       " 'minutes',\n",
       " 'remove',\n",
       " 'molds',\n",
       " 'spherical',\n",
       " 'cubes',\n",
       " 'perfectly',\n",
       " 'project',\n",
       " 'mixture',\n",
       " 'mold',\n",
       " 'either',\n",
       " 'sphere',\n",
       " 'using',\n",
       " 'half-spheres',\n",
       " 'place',\n",
       " 'refrigerator',\n",
       " 'sets',\n",
       " 'depend',\n",
       " 'three',\n",
       " 'times',\n",
       " 'wanted',\n",
       " 'attempts',\n",
       " 'trouble',\n",
       " 'problem-solve',\n",
       " ...]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'dictionary.sav'\n",
    "pickle.dump(word_features, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def document_features(document):\n",
    "    document_words = document.split()\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_set = []\n",
    "for i in range(len(train)):\n",
    "    feature_set.append((document_features(train.fullCaptions.iloc[i]), \n",
    "           train.sponsored.iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "         contains(thick) = True              yes : no     =      5.0 : 1.0\n",
      "          contains(hope) = False             yes : no     =      5.0 : 1.0\n",
      "            contains(ah) = True              yes : no     =      4.3 : 1.0\n",
      "          contains(thin) = True              yes : no     =      4.3 : 1.0\n",
      "      contains(together) = True              yes : no     =      3.7 : 1.0\n",
      "         contains(whole) = True              yes : no     =      3.7 : 1.0\n",
      "          contains(bits) = True               no : yes    =      3.7 : 1.0\n",
      "      contains(remember) = True              yes : no     =      3.7 : 1.0\n",
      "          contains(came) = True              yes : no     =      3.7 : 1.0\n",
      "       contains(coconut) = True              yes : no     =      3.7 : 1.0\n",
      "           contains(pop) = True               no : yes    =      3.7 : 1.0\n",
      "          contains(case) = True              yes : no     =      3.7 : 1.0\n",
      "       contains(cookies) = True              yes : no     =      3.7 : 1.0\n",
      "       contains(learned) = False             yes : no     =      3.4 : 1.0\n",
      "        contains(remind) = True              yes : no     =      3.0 : 1.0\n",
      "          contains(mind) = True              yes : no     =      3.0 : 1.0\n",
      "         contains(green) = True              yes : no     =      3.0 : 1.0\n",
      "          contains(whoa) = True              yes : no     =      3.0 : 1.0\n",
      "         contains(sound) = True              yes : no     =      3.0 : 1.0\n",
      "        contains(enough) = True               no : yes    =      3.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169    On my last trip to California I stopped into C...\n",
       "188    A big thank you to Progresso for sponsoring th...\n",
       "101    Visit https://squarespace.com/emmy and enter t...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.description.iloc[['mint'in cap for cap in train.captions]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spon_test = list(set(spon) - set(spon_sample))\n",
    "not_spon_test =  random.sample(list(set(not_spon) - set(not_spon_sample)),len(spon_test))\n",
    "\n",
    "test = youtube_data_from_sql.iloc[not_spon_test + spon_test, :]\n",
    "\n",
    "test_feature_set = []\n",
    "for i in range(len(test)):\n",
    "    test_feature_set.append((document_features(test.fullCaptions.iloc[i]), \n",
    "           test.sponsored.iloc[i]))\n",
    "    \n",
    "    \n",
    "nltk.classify.accuracy(classifier, test_feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>channel</th>\n",
       "      <th>title</th>\n",
       "      <th>video_id</th>\n",
       "      <th>description</th>\n",
       "      <th>captions</th>\n",
       "      <th>sponsored</th>\n",
       "      <th>fullCaptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>166</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>SPICY CHEESE RAMEN CHALLENGE</td>\n",
       "      <td>tFo-ZFxy_Tc</td>\n",
       "      <td>I found a cheesy version of the Samyang noodle...</td>\n",
       "      <td>1\\n00:00:00,000 --&gt; 00:00:03,720\\n[Music]\\n\\n2...</td>\n",
       "      <td>no</td>\n",
       "      <td>greetings uh plays hi it's Emmy welcome back t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>126</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>WAFFLE HOT DOG Recipe - Weenies</td>\n",
       "      <td>CrPXJZikzCM</td>\n",
       "      <td>Here's how to take breakfast to the next level...</td>\n",
       "      <td>1\\n00:00:00,000 --&gt; 00:00:02,360\\n[Music]\\n\\n2...</td>\n",
       "      <td>no</td>\n",
       "      <td>everybody it's me I'm back back in with a how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>123</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>$1 CHICKEN FRIED STEAK &amp; homemade gravy | DOLL...</td>\n",
       "      <td>RNQdkP0uUQc</td>\n",
       "      <td>Visit https://squarespace.com/emmy and enter t...</td>\n",
       "      <td>1\\n00:00:00,320 --&gt; 00:00:07,350\\n[Music]\\n\\n2...</td>\n",
       "      <td>yes</td>\n",
       "      <td>Greetings my lovelies~ Hi it's Emmy. Welcome b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>emmymadeinjapan</td>\n",
       "      <td>Emmy Takes the SUPERTASTER Test - counting tas...</td>\n",
       "      <td>P_8ZYxJ8ay0</td>\n",
       "      <td>Check out HELLO FRESH: http://bit.ly/2fiQBC0 a...</td>\n",
       "      <td>1\\n00:00:05,200 --&gt; 00:00:10,200\\nGreetings my...</td>\n",
       "      <td>yes</td>\n",
       "      <td>you everyone I'm back it's been a while I've n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index          channel  \\\n",
       "148    166  emmymadeinjapan   \n",
       "108    126  emmymadeinjapan   \n",
       "105    123  emmymadeinjapan   \n",
       "14      15  emmymadeinjapan   \n",
       "\n",
       "                                                 title     video_id  \\\n",
       "148                       SPICY CHEESE RAMEN CHALLENGE  tFo-ZFxy_Tc   \n",
       "108                    WAFFLE HOT DOG Recipe - Weenies  CrPXJZikzCM   \n",
       "105  $1 CHICKEN FRIED STEAK & homemade gravy | DOLL...  RNQdkP0uUQc   \n",
       "14   Emmy Takes the SUPERTASTER Test - counting tas...  P_8ZYxJ8ay0   \n",
       "\n",
       "                                           description  \\\n",
       "148  I found a cheesy version of the Samyang noodle...   \n",
       "108  Here's how to take breakfast to the next level...   \n",
       "105  Visit https://squarespace.com/emmy and enter t...   \n",
       "14   Check out HELLO FRESH: http://bit.ly/2fiQBC0 a...   \n",
       "\n",
       "                                              captions sponsored  \\\n",
       "148  1\\n00:00:00,000 --> 00:00:03,720\\n[Music]\\n\\n2...        no   \n",
       "108  1\\n00:00:00,000 --> 00:00:02,360\\n[Music]\\n\\n2...        no   \n",
       "105  1\\n00:00:00,320 --> 00:00:07,350\\n[Music]\\n\\n2...       yes   \n",
       "14   1\\n00:00:05,200 --> 00:00:10,200\\nGreetings my...       yes   \n",
       "\n",
       "                                          fullCaptions  \n",
       "148  greetings uh plays hi it's Emmy welcome back t...  \n",
       "108  everybody it's me I'm back back in with a how ...  \n",
       "105  Greetings my lovelies~ Hi it's Emmy. Welcome b...  \n",
       "14   you everyone I'm back it's been a while I've n...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('yes', 'yes')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=2\n",
    "(classifier.classify(document_features(test.fullCaptions.iloc[i])), test.sponsored.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'sponView_classifier.sav'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'sponView_classifier.sav'\n",
    "classifier = pickle.load(open(filename, 'rb'))\n",
    "nltk.classify.accuracy(classifier, test_feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('yes', 'no', 'gZe7VETOgaY')\n",
      "('no', 'no', 'LL9AG9U7Vqw')\n",
      "('yes', 'yes', 'RNQdkP0uUQc')\n",
      "('yes', 'yes', 'P_8ZYxJ8ay0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print((classifier.classify(document_features(test.fullCaptions.iloc[i])), \n",
    "           test.sponsored.iloc[i],test.video_id.iloc[i]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# flask code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "import re\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "import pickle\n",
    "\n",
    "from nltk.tokenize import word_tokenize # or use some other tokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    you everyone I'm back it's been a while I've n...\n",
       "Name: fullCaptions, dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### given video id pull captions\n",
    "######input video_id\n",
    "def get_captions(video_id):\n",
    "    ###### for MVP just take from table. for next week figure out authentication and implement parsing\n",
    "    dbname = 'youtubeSpon'\n",
    "    username = 'april' # change this to your username\n",
    "\n",
    "    engine = create_engine('postgres://%s@localhost/%s'%(username,dbname))\n",
    "    con = None\n",
    "    con = psycopg2.connect(database = dbname, user = username)\n",
    "\n",
    "    # query:\n",
    "    sql_query = \"\"\"SELECT * FROM \"youtubeEmmy\" WHERE \"youtubeEmmy\".video_id = '%s';\"\"\"%video_id\n",
    "    selectedCaption = pd.read_sql_query(sql_query,con)\n",
    "    return selectedCaption\n",
    "\n",
    "get_captions('P_8ZYxJ8ay0').fullCaptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def document_features(document):\n",
    "    document_words = document.split()\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### run classifier\n",
    "def run_classifier(video_id):\n",
    "    #load model\n",
    "    filename = 'sponView_classifier.sav'\n",
    "    classifier = pickle.load(open(filename, 'rb'))\n",
    "    captions = get_captions(video_id)\n",
    "    return classifier.classify(document_features(captions))\n",
    "    \n",
    "run_classifier('QDlbOrOO0_E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_classifier('RNQdkP0uUQc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
